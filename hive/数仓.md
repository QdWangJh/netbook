## **数仓分层带来如下的好处：**

- **数据结构化更清晰**

每一个数据分层都有它的作用域和职责，在使用表的时候能更方便地定位和理解。

- **数据血缘追踪**

提供给外界使用的是一张业务表，但是这张业务表可能来源很多张表。如果有一张来源表出问题了，我们可以快速准确的定位到问题，并清楚每张表的作用范围。

- **增强数据复用能力**

减少重复开发，通过数据分层规范化，开发一些通用的中间层数据，能够减少重复计算，提高单张业务表的使用率，提升系统的执行效率。

- **简化复杂的问题**

把一个复杂的业务分成多个步骤实现，每一层只处理单一的步骤，比较简单和容易理解。而且便于维护数据的准确性，当数据出现问题之后，可以不用修复所有的数据，只需要从有问题的步骤开始修复。

- **减少业务的影响**

业务可能会经常变化，这样做就不必改一次业务就需要重新接入数据。

- **统一数据口径**

通过数据分层，提供统一的数据出口，统一对外输出的数据口径





**三、数仓中常见的层级
**



数仓中常见的层级如下：



![图片](F:\笔记\hive\图\640.webp)



**1、****ODS(Operation Data Store)**

这层字面意思叫操作型数据存储，存储来自多个业务系统、前端埋点、爬虫获取等的一系列数据源的数据。

- 又叫“**贴源层**”，这层保持数据原貌不做任何修改，保留历史数据，储存起到备份数据的作用。
- 数据一般采用lzo、Snappy、parquet等压缩格式，减少磁盘存储空间（例如：原始数据 10G，根据算法可以压缩到 1G 左 右）。
- 创建分区表，防止后续的全表扫描，减少集群资源访问数仓的压力，一般按天存储在数仓中。

有些公司还会把ODS层再细分两层：

**STG**：数据缓冲层，存原始数据；

**ODS**：对STG层简单清洗后的数据。



**2、DW(Data Warehouse)**

数仓主体层从ODS层中获得的数据按照主题建立各种数据模型。

又细分为以下几层：

**2.1、DWD(Data Warehouse Detail)**

明细粒度事实层：是以业务过程来作为建模驱动，基于每个具体的业务过程特点，构建最细粒度的明细层事实表（注意是最细粒度）。需要结合企业的数据使用特点，将明细事实表的某些重要维度属性字段做适当冗余，即宽表化处理。明细粒度事实层的表通常也被称为**逻辑事实表**。

- DWD层是维度建模层

    关于维度建模请查阅[***数仓（三）建模和维度建模***](http://mp.weixin.qq.com/s?__biz=Mzg3ODU4ODMyOQ==&mid=2247484028&idx=1&sn=f3120d2f42ce8775faf0e5633d6f0826&chksm=cf103abaf867b3acba57474b4ca031d33018c6d4a72754dc0d2e879d3f77a1c89175a910d633&scene=21#wechat_redirect)，这层维度建模主要做的4个步骤：

![图片](F:\笔记\hive\图\640-16420763233442.webp)

- ODS到DWD层，需要对数据进行清洗做ETL操作（ETL是英文Extract-Transform-Load的缩写)。

**ETL（\**Extract-Transform-Load\**）**

将数据从来源端经过抽取(extract)、转换(transform)、加载(load)至目的端的过程。是将业务系统的数据经过抽取、清洗转换之后加载到数据仓库的过程。

目的是将企业中的分散、凌乱、标准不统一的数据整合到一起，为企业的决策提供分析依据。

- 主要的数据处理是：去空值、去极值（比方取款300亿）、去业务极值、部分数据脱敏、维度退化等即对业务数据传过来的表进行维度退化和降维（如：商品一级二级、省市县、年月日等）。

***\*2.2、DWS(Data Warehouse Service)\****

- 使轻度汇总层，从ODS层中对用户的行为做一个初步的汇总，抽象出来一些通用的维度：时间、ip、id，并根据这些维度做一些统计值。
- 这里做轻度的汇总会让以后的计算更加的高效，如：统计各个主题对象计算7天、30天、90天的行为， 应对特殊需求（例如，购买行为，统计商品复购率）会快很多不必走ODS层反复拿数据做加工。
- 这层以分析的主题对象作为建模驱动，基于上层的应用和产品的指标需求，构建公共粒度的汇总指标事实表，以宽表化手段物理化模型。构建命名规范、口径一致的统计指标，为上层提供公共指标，建立汇总宽表、明细事实表。
- 服务于 DWT 层的主题宽表，以及一些业务明细数据。

**2.3、DWT(Data Warehouse Topic)**

以分析的主题对象为建模驱动，基于上层的应用和产品的指标需求，构建主题对象的全量宽表。就是按照维度来决定分析者的角度，如：某用户从注册登录后下了多少订单。

**2.4、DIM（Dimension）**

以维度作为建模驱动，基于每个维度的业务含义，通过添加维度属性、关联维度等定义计算逻辑，完成属性定义的过程并建立一致的数据分析维表。为了避免在维度模型中冗余关联维度的属性，基于雪花模型构建维度表。维度层的表通常也被称为维度逻辑表。

- **高基数维度数据**

    一般是用户资料表、商品资料表等类似的资料表。数据量可能是千万级或者上亿级别。

- **低基数维度数据**

    一般是配置表，比如枚举值对应的中文含义，比如国家、城市、县市、街道等维表。数据量可能是个位数或者几千几万。

**3、ADS(Application Data Store)**

供给业务使用的数据层，这层是面向业务定制的应用数据层。

- 这一层是提供为数据产品使用的结果数据。
- 在这里，主要是提供给数据产品和数据分析使用的数据，一般会存放在 ES、MySQL等系统中供线上系统使用，也可能会存在 Hive 或者 Druid 、kill中供数据分析和数据挖掘使用。如我们经常说的报表数据，或者说那种大宽表，一般就放在这里。

**4、DM（Data Mart）**

数据集市层，上面已经讨论过数据集市的概念，这层就是对不同的主题域，对某个单独业务或者部门专门设立的小型数据集市。



下一篇会精选了几个大厂的数仓分层架构的典型代表，来加深对数仓分层架构的理解、希望对我们设计和构建数仓分层模型，能有所借鉴或启迪。



*数仓分几层适合？有没有统一的标准**



**A：** 我们设计数仓分层的时候，要考虑到公司或者部门的实际需要来对数仓分层。如果你负责的仅仅是一个小部门的数据，而公司已经有一个数仓平台了。那么你或许仅需要构建一个你自己的应用层，或者集市层，根本无需分层。

如果一般大的公司有公共IT部门，该部门会构建统一数仓，如主数据，如统一交易表，统一埋点或者标准维度表等。当然大一点的事业群或者事业部会构建自己的数仓层，有一些部门特有的业务数据。可以构建简单三层模型即ODS + DW + ADS。



## 案例

### **一、ODS层数据搭建前提工作**

ODS搭建的前提条件是业务系统（如：javaweb）前端的埋点日志信息、以及业务数据（存储在mysql）以及采集到了HDFS平台上了。假设现在业务系统(如：javaweb)的埋点日志信息、以及业务交易数据（存储在mysql）已经都采集到了HDFS平台。

[Flume NG：Flume 发展史上的第一次革命](http://mp.weixin.qq.com/s?__biz=MzUyMDA4OTY3MQ==&mid=2247487188&idx=1&sn=7062e3837532cafa73d379ff2f4c1fc3&chksm=f9eef7fcce997eeaf4d35437a4abe2ae3b8698033e2a589848e3a790cbac00b1f980296168b1&scene=21#wechat_redirect)

[Flume+Kafka双剑合璧玩转大数据平台日志采集](http://mp.weixin.qq.com/s?__biz=MzUyMDA4OTY3MQ==&mid=2247501975&idx=1&sn=951f8bc29616678f09d84d1c9ee97a13&chksm=f9ed31bfce9ab8a967bde752283dc23353f4cc53945b096d108d389dea72e16faf5018d4df64&scene=21#wechat_redirect)

[埋点治理：如何把App埋点做到极致？](http://mp.weixin.qq.com/s?__biz=MzUyMDA4OTY3MQ==&mid=2247492315&idx=2&sn=0d55f52518cff3c5fd0c8d9caac6c76a&chksm=f9ed1bf3ce9a92e539ec556a2430dca569c830d04d3dac9861947fab43859b3f1a82745fd64f&scene=21#wechat_redirect)

[知乎数据埋点方案](http://mp.weixin.qq.com/s?__biz=MzUyMDA4OTY3MQ==&mid=2247487158&idx=1&sn=d9981190ebed0ed9ff685fe81778a62c&chksm=f9eef79ece997e88dc2f4f4358f1c847b3c56175cf1c8e13d89449f7cdff5a33af1915318a69&scene=21#wechat_redirect)



### 二、ODS层（埋点日志处理）

首先我们回顾一下ODS层的主要作用和特点：

**ODS(Operation Data Store)**

这层字面意思叫操作型数据存储，存储来自多个业务系统、前端埋点、爬虫获取等的一系列数据源的数据。

- 又叫“**贴源层**”，这层保持数据原貌不做任何修改，保留历史数据，储存起到备份数据的作用。
- 数据一般采用lzo、Snappy、parquet等压缩格式，减少磁盘存储空间（例如：原始数据 10G，根据算法可以压缩到 1G 左 右）。
- 创建分区表，防止后续的全表扫描，减少集群资源访问数仓的压力，一般按天存储在数仓中。

有些公司还会把ODS层再细分两层：

**STG**：数据缓冲层，存原始数据；

**ODS**：对STG层简单清洗后的数据。



### **1、创建前端埋点日志ods_log表**

前端埋点日志信息都是JSON格式形式主要包括两方面：

（1）启动日志；（2）事件日志：

![图片](F:\笔记\hive\图\640-16421291343494.webp)



我们把前端整个1条记录埋点日志，当一个字符串来处理，传入到hive数据库。

**创建HQL语句如下：**

在DataGrip里面执行

```sql
drop table if exists ods_log;create external table ods_log(line string)partitioned by (dt string)Stored as    inputformat 'com.hadoop.mapred.DeprecatedLzoTextInputFormat'    outputformat 'org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat'Location '/warehouse/gmail/ods/ods_log';
```



**添加lzo索引**

还需要在hive文件上，添加lzo索引，要不然无法支持切片操作。

具体做法是通过hadoop自带的jar包在hadoop集群命令行里面执行：

```sql
hadoop jar /opt/module/hadoop-3.1.4/share/hadoop/common/hadoop-lzo-0.4.20.jar   com.hadoop.compression.lzo.DistributedLzoIndexer   -Dmapreduce.job.queuename=hive   /warehouse/gmail/ods/ods_log/dt=2021-05-01
```



### 2、执行完，观察Browser Director

发现已经多了lzo.index索引

![图片](F:\笔记\hive\图\640-16421291310352.webp)



**3、加载读取HDFS数据到hive

```
load data inpath '/origin_data/gmall/log/topic_log/2021-05-01'    into table ods_log partition (dt='2021-05-01');
```

源路径在

HDFS上/origin_data/gmall/log/topic_log/2021-05-01



![图片](F:\笔记\hive\图\640.webp)



加载到hive，路径是

/warehouse/gmail/ods/ods_log/dt=2021-05-01



![图片](F:\笔记\hive\图\640-16421291424138.webp)



load做的是剪切的操作！



**4、查看hive库数据是否已经加载成功？**

![图片](F:\笔记\hive\图\640-16421291395076.webp)



这样我们就完成了ODS层前端埋点日志的处理。



### 三、ODS层（业务数据处理）

**

现在我们来处理ODS层业务数据，先需要回顾一下ODS层当时建表的表结构关系。

**1、业务表逻辑结构关系**

![图片](F:\笔记\hive\图\640-164212914831910.webp)

其中有颜色填充的代表：事实表；

其他：代表维度表；

**2、HDFS文件对应hive表结构关系**

![图片](F:\笔记\hive\图\640-164212915025812.webp)



源业务系统javaweb项目中的数据存储在mysql里面，通过sqoop采集到HDFS对应的文件，需要在hive数仓里面设计外部表与其一一对应；

（1）考虑到分区partitioned by 时间

（2）考虑到lzo压缩，并且需要lzo压缩支持切片的话，必须要添加lzo索引

（3）mysql数据库的表通过sqoop采集到HDFS，用的是\t作为分割，那数仓里面ODS层也需要\t作为分割；

![图片](F:\笔记\hive\图\640-164212915290914.webp)



**3、创建ODS层业务表**

这里我们业务系统javaweb项目一共有23张表，数仓hive我们这里只演示创建三张代表性的表。因为23张创建表的结构大都一样，这里只有3种数据同步策略的方式。

![图片](F:\笔记\hive\图\640-164212915546416.webp)



- ##### 订单表ods_order_info

    ##### 表数据同步更新策略：增量

```sql
drop table if exists ods_order_info;create external table ods_order_info (    `id` string COMMENT '订单号',    `final_total_amount` decimal(16,2) COMMENT '订单金额',    `order_status` string COMMENT '订单状态',    `user_id` string COMMENT '用户id',    `out_trade_no` string COMMENT '支付流水号',    `create_time` string COMMENT '创建时间',    `operate_time` string COMMENT '操作时间',    `province_id` string COMMENT '省份ID',    `benefit_reduce_amount` decimal(16,2) COMMENT '优惠金额',    `original_total_amount` decimal(16,2)  COMMENT '原价金额',    `feight_fee` decimal(16,2)  COMMENT '运费') COMMENT '订单表'PARTITIONED BY (`dt` string) -- 按照时间创建分区row format delimited fields terminated by '\t' -- 指定分割符为\t STORED AS -- 指定存储方式，读数据采用LzoTextInputFormat；输出数据采用TextOutputFormat  INPUTFORMAT 'com.hadoop.mapred.DeprecatedLzoTextInputFormat'  OUTPUTFORMAT 'org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat'location '/warehouse/gmail/ods/ods_order_info/'; -- 指定数据在hdfs上的存储位置
```

- ##### SKU商品表ods_sku_info表

    ##### 数据同步更新策略：全量

```sql
drop table if exists ods_sku_info;create external table ods_sku_info(     `id` string COMMENT 'skuId',    `spu_id` string   COMMENT 'spuid',     `price` decimal(16,2) COMMENT '价格',    `sku_name` string COMMENT '商品名称',    `sku_desc` string COMMENT '商品描述',    `weight` string COMMENT '重量',    `tm_id` string COMMENT '品牌id',    `category3_id` string COMMENT '品类id',    `create_time` string COMMENT '创建时间') COMMENT 'SKU商品表'PARTITIONED BY (`dt` string)row format delimited fields terminated by '\t'STORED AS  INPUTFORMAT 'com.hadoop.mapred.DeprecatedLzoTextInputFormat'  OUTPUTFORMAT 'org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat'location '/warehouse/gmail/ods/ods_sku_info/';
```

- ##### **省份表ods_base_province**

    ##### 数据同步更新策略：特殊一次性全部加载

    ##### 不做分区partitioned BY



```sql
drop table if exists ods_base_province;create external table ods_base_province (    `id`   bigint COMMENT '编号',    `name`        string COMMENT '省份名称',    `region_id`    string COMMENT '地区ID',    `area_code`    string COMMENT '地区编码',    `iso_code` string COMMENT 'iso编码,superset可视化使用')  COMMENT '省份表'row format delimited fields terminated by '\t'STORED AS  INPUTFORMAT 'com.hadoop.mapred.DeprecatedLzoTextInputFormat'  OUTPUTFORMAT 'org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat'location '/warehouse/gmail/ods/ods_base_province/';
```



**4、加载数据**

```sql
load data   inpath '/origin_data/gmall/db/order_info/XXXX-XX-XX'   OVERWRITE into table gmail.ods_order_info partition(dt='XXXX-XX-XX');
```

显示如下：

![图片](https://mmbiz.qpic.cn/mmbiz_png/EGZ1ibxgFrbgQdiafLbcgtRlZb7M6ickiav21ayOqRTge1nMMerTs9qn91pbzQJzuekh5JJzNibfdM9RwkgyYpta09Q/640?wx_fmt=png&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1)